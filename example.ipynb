{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import OrderedDict\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append('/workspace/shared_workspace/deep-learning-models/models/vision/detection/')\n",
    "import tensorflow as tf\n",
    "import horovod.tensorflow as hvd\n",
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from awsdet.datasets.coco import CocoDataset\n",
    "from awsdet.datasets.data_generator import DataGenerator\n",
    "from awsdet.datasets.loader.build_loader import build_dataloader\n",
    "\n",
    "from awsdet.models.backbones import keras_backbone\n",
    "from awsdet.models.necks import fpn\n",
    "from awsdet.models.anchor_heads.rpn_head import RPNHead\n",
    "from awsdet.core.bbox.bbox_target import ProposalTarget\n",
    "from awsdet.models.roi_extractors.roi_align import PyramidROIAlign\n",
    "from awsdet.models.bbox_heads.bbox_head import BBoxHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.15s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/workspace/shared_workspace/data/coco/coco/'\n",
    "subset = 'train'\n",
    "# create a training dataset\n",
    "coco_dataset = CocoDataset(dataset_dir, subset, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_batch_size=2\n",
    "coco_tdf = iter(build_dataloader(coco_dataset, local_batch_size)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = keras_backbone.KerasBackbone('ResNet50V1')\n",
    "neck = fpn.FPN()\n",
    "rpn_head = RPNHead()\n",
    "bbox_target = ProposalTarget()\n",
    "bbox_roi_extractor = PyramidROIAlign(pool_shape=[7, 7], pool_type='avg')\n",
    "bbox_head = BBoxHead(81, (7, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new loop for GPU: 0\n"
     ]
    }
   ],
   "source": [
    "imgs, img_meta, gt_bboxes, gt_labels = next(coco_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C2, C3, C4, C5 = backbone(imgs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "P2, P3, P4, P5, P6 = neck([C2, C3, C4, C5], training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_feature_maps = [P2, P3, P4, P5, P6]\n",
    "rcnn_feature_maps = [P2, P3, P4, P5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_class_logits, rpn_probs, rpn_deltas = rpn_head(rpn_feature_maps, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals_list = rpn_head.get_proposals(\n",
    "                    rpn_probs, rpn_deltas, img_meta, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_list, gt_assignment, rcnn_target_matchs, \\\n",
    "    rcnn_target_deltas, inside_weights, outside_weights = \\\n",
    "    bbox_target.build_targets(proposals_list, gt_bboxes, gt_labels, img_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_pooled_regions_list = bbox_roi_extractor(\n",
    "            (rois_list, rcnn_feature_maps, img_meta), training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_class_logits, rcnn_probs, rcnn_deltas = \\\n",
    "                bbox_head(bbox_pooled_regions_list, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_inputs = (rpn_class_logits, rpn_deltas, gt_bboxes, gt_labels, img_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpn_class_loss, rpn_bbox_loss = rpn_head.loss(rpn_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_inputs = (rcnn_class_logits, rcnn_deltas, rcnn_target_matchs,\n",
    "                rcnn_target_deltas, inside_weights, outside_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcnn_class_loss, rcnn_bbox_loss = bbox_head.loss(rcnn_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_dict = {\n",
    "                'rpn_class_loss': rpn_class_loss,\n",
    "                'rpn_bbox_loss': rpn_bbox_loss,\n",
    "                'rcnn_class_loss': rcnn_class_loss,\n",
    "                'rcnn_bbox_loss': rcnn_bbox_loss\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rpn_class_loss': <tf.Tensor: shape=(), dtype=float32, numpy=1.2592322>,\n",
       " 'rpn_bbox_loss': <tf.Tensor: shape=(), dtype=float32, numpy=2.4125695>,\n",
       " 'rcnn_class_loss': <tf.Tensor: shape=(), dtype=float32, numpy=9.188705>,\n",
       " 'rcnn_bbox_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.018615035>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now build as a model to train\n",
    "\n",
    "class FRCNN(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = keras_backbone.KerasBackbone('ResNet50V1')\n",
    "        self.neck = fpn.FPN()\n",
    "        self.rpn_head = RPNHead()\n",
    "        self.bbox_target = ProposalTarget()\n",
    "        self.bbox_roi_extractor = PyramidROIAlign(pool_shape=[7, 7], pool_type='avg')\n",
    "        self.bbox_head = BBoxHead(81, (7, 7))\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        imgs, img_meta, gt_bboxes, gt_labels = inputs\n",
    "        C2, C3, C4, C5 = self.backbone(imgs, training=True)\n",
    "        P2, P3, P4, P5, P6 = self.neck([C2, C3, C4, C5], training=True)\n",
    "        rpn_feature_maps = [P2, P3, P4, P5, P6]\n",
    "        rcnn_feature_maps = [P2, P3, P4, P5]\n",
    "        rpn_class_logits, rpn_probs, rpn_deltas = self.rpn_head(rpn_feature_maps, training=True)\n",
    "        proposals_list = self.rpn_head.get_proposals(\n",
    "                    rpn_probs, rpn_deltas, img_meta, training=True)\n",
    "        rois_list, gt_assignment, rcnn_target_matchs, \\\n",
    "            rcnn_target_deltas, inside_weights, outside_weights = \\\n",
    "            self.bbox_target.build_targets(proposals_list, gt_bboxes, gt_labels, img_meta)\n",
    "        bbox_pooled_regions_list = self.bbox_roi_extractor(\n",
    "            (rois_list, rcnn_feature_maps, img_meta), training=True)\n",
    "        rcnn_class_logits, rcnn_probs, rcnn_deltas = \\\n",
    "                self.bbox_head(bbox_pooled_regions_list, training=True)\n",
    "        rpn_inputs = (rpn_class_logits, rpn_deltas, gt_bboxes, gt_labels, img_meta)\n",
    "        rpn_class_loss, rpn_bbox_loss = self.rpn_head.loss(rpn_inputs)\n",
    "        rcnn_inputs = (rcnn_class_logits, rcnn_deltas, rcnn_target_matchs,\n",
    "                rcnn_target_deltas, inside_weights, outside_weights)\n",
    "        rcnn_class_loss, rcnn_bbox_loss = self.bbox_head.loss(rcnn_inputs)\n",
    "        losses_dict = {\n",
    "                'rpn_class_loss': rpn_class_loss,\n",
    "                'rpn_bbox_loss': rpn_bbox_loss,\n",
    "                'rcnn_class_loss': rcnn_class_loss,\n",
    "                'rcnn_bbox_loss': rcnn_bbox_loss\n",
    "            }\n",
    "        losses_dict['reg_loss'] = tf.add_n(self.losses)\n",
    "        local_batch_size = tf.cast(tf.shape(imgs)[0], tf.float32)\n",
    "        loss = self.parse_losses(losses_dict, local_batch_size)\n",
    "        return loss\n",
    "    \n",
    "    def parse_losses(self, losses, local_batch_size):\n",
    "        log_vars = OrderedDict()\n",
    "        for loss_name, loss_value in losses.items():\n",
    "            if tf.is_tensor(loss_value):\n",
    "                log_vars[loss_name] = tf.reduce_mean(loss_value)\n",
    "            elif isinstance(loss_value, list):\n",
    "                log_vars[loss_name] = tf.add_n(\n",
    "                    [tf.reduce_mean(_loss) for _loss in loss_value])\n",
    "            else:\n",
    "                raise TypeError(\n",
    "                    '{} is not a tensor or list of tensors'.format(loss_name))\n",
    "        loss_list = []\n",
    "        for _key, _value in log_vars.items():\n",
    "            if 'loss' in _key:\n",
    "                if 'reg_loss' not in _key:\n",
    "                    loss_list.append(_value/local_batch_size) # horovod averages (not sums) gradients by default over workers\n",
    "                else:\n",
    "                    loss_list.append(_value)\n",
    "        total_loss = sum(loss_list) \n",
    "        # log_vars['loss'] = total_loss\n",
    "        return total_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FRCNN()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.7, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = model(inputs)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c66932a7ba4a3c88777e0267619b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progressbar = tqdm(range(1000))\n",
    "\n",
    "for batch in progressbar:\n",
    "    loss = train_step(next(coco_tdf))\n",
    "    progressbar.set_description(\"Loss: {0:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
